{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile men_names.txt\n",
        "Aleksander\n",
        "Maxim\n",
        "Artyom\n",
        "Mikhail\n",
        "Ivan\n",
        "Daniel\n",
        "Danila\n",
        "Danil\n",
        "Dmitriy\n",
        "Kirill\n",
        "Andrei\n",
        "Egor\n",
        "Igor\n",
        "Nikita\n",
        "Ilya\n",
        "Alexei\n",
        "Matvey\n",
        "Timofey\n",
        "Novel\n",
        "Vladimir\n",
        "Yaroslav\n",
        "Fedor\n",
        "Fyodor\n",
        "Gleb\n",
        "George\n",
        "Konstantin\n",
        "Lev\n",
        "Leo\n",
        "Nikolay\n",
        "Stepan\n",
        "Vladislav\n",
        "Pavel\n",
        "Arseny\n",
        "Denis\n",
        "Timur\n",
        "Abram\n",
        "Albert\n",
        "Alyosha\n",
        "Anastas\n",
        "Anatoly\n",
        "Anton\n",
        "Arkady\n",
        "Artemy\n",
        "Artur\n",
        "Afanasy\n",
        "Bogdan\n",
        "Boris\n",
        "Budimir\n",
        "Damien\n",
        "David\n",
        "Denis\n",
        "Eduard\n",
        "Erik\n",
        "Evgeny\n",
        "Garry\n",
        "Gavriil\n",
        "Gennady\n",
        "Georgy\n",
        "Gerasim\n",
        "German\n",
        "Grigory\n",
        "Ignat\n",
        "Ignaty\n",
        "Illarion\n",
        "Ilia\n",
        "Immanuil\n",
        "Iosif\n",
        "Leonid\n",
        "Luka\n",
        "Makar\n",
        "Marat\n",
        "Mark\n",
        "Milan\n",
        "Nestor\n",
        "Oleg\n",
        "Osip\n",
        "Pavel\n",
        "Pyotr\n",
        "Peter\n",
        "Petr\n",
        "Radomir\n",
        "Robert\n",
        "Rodion\n",
        "Roman\n",
        "Rostislav\n",
        "Ruslan\n",
        "Samuil\n",
        "Semyon\n",
        "Sergei\n",
        "Spartak\n",
        "Stanislav\n",
        "Taras\n",
        "Trofim\n",
        "Vadim\n",
        "Valentin\n",
        "Valery\n",
        "Vasily\n",
        "Veniamin\n",
        "Viktor\n",
        "Vitaly\n",
        "Vlad\n",
        "Vsevolod\n",
        "Vyacheslav\n",
        "Yakov\n",
        "Yegor\n",
        "Yefim\n",
        "Yulian\n",
        "Yury\n",
        "Zakhar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT3uSLP5kd0U",
        "outputId": "48af8204-2702-4982-f558-08b59bb0380f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting men_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import typing as t\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "X46HxnOMm9Gq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_char_vocab(filename: str) -> t.Dict[str, int]:\n",
        "  vocab = {\n",
        "      '<start>': 0,\n",
        "      '<end>': 1,\n",
        "      '<pad>': 2,\n",
        "      '<unk>': 3\n",
        "  }\n",
        "\n",
        "  with open(filename, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      for char in line:\n",
        "        if char == '\\n':\n",
        "          continue\n",
        "        if char not in vocab:\n",
        "          vocab[char] = len(vocab)\n",
        "  return vocab\n",
        "\n",
        "\n",
        "def text_to_ids(\n",
        "    vocab: t.Dict[str, int],\n",
        "    texts: t.List[t.List[str]],\n",
        "    max_len: int\n",
        ") -> t.List[t.List[int]]:\n",
        "\n",
        "  output = []\n",
        "  for text in texts:\n",
        "    text = text.replace('\\n', '')\n",
        "    if len(text) > max_len and max_len > 2:\n",
        "      cut_off_index = max_len - 2 # <start> + <end> tokens\n",
        "      text = text[:cut_off_index]\n",
        "\n",
        "    raw_token_ids = [vocab.get(char, vocab['<unk>']) for char in text]\n",
        "\n",
        "    n_paddings = max_len - (len(text) + 2)\n",
        "    raw_token_ids = [vocab['<start>']] + raw_token_ids + [vocab['<end>']]\n",
        "    padded_token_ids = raw_token_ids + [vocab['<pad>']] * n_paddings\n",
        "\n",
        "    assert len(padded_token_ids) == max_len, f'{len(padded_token_ids)} {max_len}'\n",
        "\n",
        "    output.append(padded_token_ids)\n",
        "  return output\n",
        "\n",
        "\n",
        "def ids_to_text(\n",
        "    vocab: t.Dict[str, int],\n",
        "    token_ids: t.List[int]\n",
        ") -> t.List[t.List[str]]:\n",
        "\n",
        "  output = []\n",
        "  id2char = {pos: char for char, pos in vocab.items()}\n",
        "\n",
        "  for ids in token_ids:\n",
        "    text_tokens = [id2char[_id] for _id in ids]\n",
        "    output.append(text_tokens)\n",
        "  return output"
      ],
      "metadata": {
        "id": "uowLaDoxnGxk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_char_vocab('men_names.txt')"
      ],
      "metadata": {
        "id": "PnXnxL0NpwSV"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_ids(vocab, ['kek lol'], max_len=12)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEY0SbAdqjjF",
        "outputId": "d4953747-7318-4e99-cd00-0cb5f042aa34"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 7, 6, 7, 3, 5, 19, 5, 1, 2, 2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_text(vocab, text_to_ids(vocab, ['kek lol'], max_len=12))[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-iEVJmGsiny",
        "outputId": "a42df804-316c-44cc-fcf0-734f60796fcd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start>',\n",
              " 'k',\n",
              " 'e',\n",
              " 'k',\n",
              " '<unk>',\n",
              " 'l',\n",
              " 'o',\n",
              " 'l',\n",
              " '<end>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_training_pairs(vocab: t.Dict[str, int], text: str, max_len: int, context_length: int):\n",
        "  ids = text_to_ids(vocab, [text], max_len=max_len)[0]\n",
        "  next_ids = ids[1:] + [vocab['<pad>']]\n",
        "  print('ids \\t', ids)\n",
        "  print('next ids', next_ids)\n",
        "  print()\n",
        "\n",
        "  for t in range(len(ids) - 1):\n",
        "    start = max(0, t - context_length)\n",
        "    tokens = ids[start: t + 1]\n",
        "    next_tokens = next_ids[start: t + 1]\n",
        "    print('tokens \\t\\t', tokens)\n",
        "    print('next_tokens \\t', next_tokens)\n",
        "    print('after', tokens[:t + 1], 'goes', next_ids[t])\n",
        "    print('-' * 80)\n",
        "    yield tokens, next_ids[t]"
      ],
      "metadata": {
        "id": "VPj3N0birCeD"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for source, target in build_training_pairs(vocab, text='kek lol arbidol', max_len=len('kek lol arbidol') + 2, context_length=6):\n",
        "  print(source, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3yDvVeisxk2",
        "outputId": "a8e57c4c-b843-4840-808f-66454fd04e5a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ids \t [0, 7, 6, 7, 3, 5, 19, 5, 3, 9, 12, 34, 15, 11, 19, 5, 1]\n",
            "next ids [7, 6, 7, 3, 5, 19, 5, 3, 9, 12, 34, 15, 11, 19, 5, 1, 2]\n",
            "\n",
            "tokens \t\t [0]\n",
            "next_tokens \t [7]\n",
            "after [0] goes 7\n",
            "--------------------------------------------------------------------------------\n",
            "[0] 7\n",
            "tokens \t\t [0, 7]\n",
            "next_tokens \t [7, 6]\n",
            "after [0, 7] goes 6\n",
            "--------------------------------------------------------------------------------\n",
            "[0, 7] 6\n",
            "tokens \t\t [0, 7, 6]\n",
            "next_tokens \t [7, 6, 7]\n",
            "after [0, 7, 6] goes 7\n",
            "--------------------------------------------------------------------------------\n",
            "[0, 7, 6] 7\n",
            "tokens \t\t [0, 7, 6, 7]\n",
            "next_tokens \t [7, 6, 7, 3]\n",
            "after [0, 7, 6, 7] goes 3\n",
            "--------------------------------------------------------------------------------\n",
            "[0, 7, 6, 7] 3\n",
            "tokens \t\t [0, 7, 6, 7, 3]\n",
            "next_tokens \t [7, 6, 7, 3, 5]\n",
            "after [0, 7, 6, 7, 3] goes 5\n",
            "--------------------------------------------------------------------------------\n",
            "[0, 7, 6, 7, 3] 5\n",
            "tokens \t\t [0, 7, 6, 7, 3, 5]\n",
            "next_tokens \t [7, 6, 7, 3, 5, 19]\n",
            "after [0, 7, 6, 7, 3, 5] goes 19\n",
            "--------------------------------------------------------------------------------\n",
            "[0, 7, 6, 7, 3, 5] 19\n",
            "tokens \t\t [0, 7, 6, 7, 3, 5, 19]\n",
            "next_tokens \t [7, 6, 7, 3, 5, 19, 5]\n",
            "after [0, 7, 6, 7, 3, 5, 19] goes 5\n",
            "--------------------------------------------------------------------------------\n",
            "[0, 7, 6, 7, 3, 5, 19] 5\n",
            "tokens \t\t [7, 6, 7, 3, 5, 19, 5]\n",
            "next_tokens \t [6, 7, 3, 5, 19, 5, 3]\n",
            "after [7, 6, 7, 3, 5, 19, 5] goes 3\n",
            "--------------------------------------------------------------------------------\n",
            "[7, 6, 7, 3, 5, 19, 5] 3\n",
            "tokens \t\t [6, 7, 3, 5, 19, 5, 3]\n",
            "next_tokens \t [7, 3, 5, 19, 5, 3, 9]\n",
            "after [6, 7, 3, 5, 19, 5, 3] goes 9\n",
            "--------------------------------------------------------------------------------\n",
            "[6, 7, 3, 5, 19, 5, 3] 9\n",
            "tokens \t\t [7, 3, 5, 19, 5, 3, 9]\n",
            "next_tokens \t [3, 5, 19, 5, 3, 9, 12]\n",
            "after [7, 3, 5, 19, 5, 3, 9] goes 12\n",
            "--------------------------------------------------------------------------------\n",
            "[7, 3, 5, 19, 5, 3, 9] 12\n",
            "tokens \t\t [3, 5, 19, 5, 3, 9, 12]\n",
            "next_tokens \t [5, 19, 5, 3, 9, 12, 34]\n",
            "after [3, 5, 19, 5, 3, 9, 12] goes 34\n",
            "--------------------------------------------------------------------------------\n",
            "[3, 5, 19, 5, 3, 9, 12] 34\n",
            "tokens \t\t [5, 19, 5, 3, 9, 12, 34]\n",
            "next_tokens \t [19, 5, 3, 9, 12, 34, 15]\n",
            "after [5, 19, 5, 3, 9, 12, 34] goes 15\n",
            "--------------------------------------------------------------------------------\n",
            "[5, 19, 5, 3, 9, 12, 34] 15\n",
            "tokens \t\t [19, 5, 3, 9, 12, 34, 15]\n",
            "next_tokens \t [5, 3, 9, 12, 34, 15, 11]\n",
            "after [19, 5, 3, 9, 12, 34, 15] goes 11\n",
            "--------------------------------------------------------------------------------\n",
            "[19, 5, 3, 9, 12, 34, 15] 11\n",
            "tokens \t\t [5, 3, 9, 12, 34, 15, 11]\n",
            "next_tokens \t [3, 9, 12, 34, 15, 11, 19]\n",
            "after [5, 3, 9, 12, 34, 15, 11] goes 19\n",
            "--------------------------------------------------------------------------------\n",
            "[5, 3, 9, 12, 34, 15, 11] 19\n",
            "tokens \t\t [3, 9, 12, 34, 15, 11, 19]\n",
            "next_tokens \t [9, 12, 34, 15, 11, 19, 5]\n",
            "after [3, 9, 12, 34, 15, 11, 19] goes 5\n",
            "--------------------------------------------------------------------------------\n",
            "[3, 9, 12, 34, 15, 11, 19] 5\n",
            "tokens \t\t [9, 12, 34, 15, 11, 19, 5]\n",
            "next_tokens \t [12, 34, 15, 11, 19, 5, 1]\n",
            "after [9, 12, 34, 15, 11, 19, 5] goes 1\n",
            "--------------------------------------------------------------------------------\n",
            "[9, 12, 34, 15, 11, 19, 5] 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NamesDataset(Dataset):\n",
        "\n",
        "  def __init__(self, filename: str) -> None:\n",
        "    self.all_texts: t.List[str] = []\n",
        "    self.max_len: int = 0\n",
        "    self._vocab: t.Dict[str, int] = build_char_vocab(filename)\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "      for line in f.readlines():\n",
        "        line = line.replace('\\n', '')\n",
        "        self.all_texts.append(line)\n",
        "        if len(line) > self.max_len:\n",
        "          self.max_len = len(line)\n",
        "\n",
        "  @property\n",
        "  def vocab(self) -> t.Dict[str, int]:\n",
        "    return self._vocab\n",
        "\n",
        "  def __getitem__(self, index: int) -> t.Dict[str, torch.LongTensor]:\n",
        "    source_text = self.all_texts[index]\n",
        "    # print('source_text', source_text)\n",
        "    source_token_ids = text_to_ids(self._vocab, [source_text], max_len=self.max_len + 2)[0]\n",
        "    # print('source_token_ids', source_token_ids)\n",
        "\n",
        "    target_token_ids = source_token_ids[1:] + [self.vocab['<pad>']]\n",
        "    # print('target_token_ids', target_token_ids)\n",
        "    target_text = ids_to_text(self._vocab, [target_token_ids])\n",
        "    # print('target_text', target_text)\n",
        "\n",
        "    source_token_ids_pt = torch.LongTensor(source_token_ids)\n",
        "    target_token_ids_pt = torch.LongTensor(target_token_ids)\n",
        "\n",
        "    return {\n",
        "        'source_ids': source_token_ids_pt,\n",
        "        'target_ids': target_token_ids_pt\n",
        "    }\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.all_texts)"
      ],
      "metadata": {
        "id": "bksDJQ9RtXIY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      vocab: t.Dict[int, int],\n",
        "      embedding_dim: int = 256,\n",
        "      hidden_size: int = 128,\n",
        "      num_layers: int = 2,\n",
        "      dropout: float = 0.2\n",
        "  ) -> None:\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.char_embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "    self.rnn = nn.LSTM(\n",
        "        input_size=embedding_dim,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        batch_first=True,\n",
        "        dropout=dropout,\n",
        "        bidirectional=False\n",
        "    )\n",
        "    self.clf = nn.Linear(hidden_size, len(vocab))\n",
        "\n",
        "    pad_token_idx = vocab.get('<pad>', -1)\n",
        "    if pad_token_idx != -1:\n",
        "      self.char_embedding.weight.data[pad_token_idx].fill_(0)\n",
        "\n",
        "  def init_hidden_and_cell(self, batch_size: int) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
        "    hidden = torch.zeros((self.num_layers, batch_size, self.hidden_size))\n",
        "    cell = torch.zeros((self.num_layers, batch_size, self.hidden_size))\n",
        "    return hidden, cell\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      x: torch.Tensor,\n",
        "      hidden_and_cell: torch.Tensor\n",
        "  ) -> t.Tuple[torch.Tensor, t.Tuple[torch.Tensor, torch.Tensor]]:\n",
        "    # Forward pass\n",
        "    embeddings = self.char_embedding(x)\n",
        "    output, (hidden, cell) = self.rnn(embeddings)\n",
        "    # output = output.reshape(-1, self.hidden_size)\n",
        "    # print(output.shape, hidden.shape, cell.shape)\n",
        "    return self.clf(output), (hidden, cell)"
      ],
      "metadata": {
        "id": "eF1qh7FK4siU"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_batch(\n",
        "    vocab: t.Dict[str, int],\n",
        "    text: t.List[str]\n",
        ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "  source_text = text_to_ids(vocab, [text], max_len=len(text) + 2)[0]\n",
        "  target_text = source_text[1:] + [vocab['<pad>']]\n",
        "\n",
        "  for t in range(len(source_text)):\n",
        "    iter_source_ids = source_text[:t + 1]\n",
        "    iter_target_text = target_text[:t + 1:]\n",
        "    yield torch.LongTensor([iter_source_ids]), torch.LongTensor([iter_target_text])\n",
        "\n",
        "\n",
        "def create_train_batch_v2(\n",
        "    vocab: t.Dict[str, int],\n",
        "    text: t.List[str],\n",
        "    context_length: int\n",
        ") -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "  source_text = text_to_ids(vocab, [text], max_len=len(text) + 2)[0]\n",
        "  target_text = source_text + [vocab['<pad>']]\n",
        "  for t in range(1, len(source_text)):\n",
        "    start = max(0, t - context_length)\n",
        "    iter_source_ids = source_text[start: t]\n",
        "    next_char = target_text[t]\n",
        "    yield torch.LongTensor([iter_source_ids]), torch.LongTensor([next_char])"
      ],
      "metadata": {
        "id": "KXCUh2O8V5fW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for source, target in create_train_batch(vocab, text='kek lol'):\n",
        "  print(source, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdtuZmMrXesP",
        "outputId": "46b3f208-a15a-443d-b89d-137293f7ddd4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0]]) tensor([[7]])\n",
            "tensor([[0, 7]]) tensor([[7, 6]])\n",
            "tensor([[0, 7, 6]]) tensor([[7, 6, 7]])\n",
            "tensor([[0, 7, 6, 7]]) tensor([[7, 6, 7, 3]])\n",
            "tensor([[0, 7, 6, 7, 3]]) tensor([[7, 6, 7, 3, 5]])\n",
            "tensor([[0, 7, 6, 7, 3, 5]]) tensor([[ 7,  6,  7,  3,  5, 19]])\n",
            "tensor([[ 0,  7,  6,  7,  3,  5, 19]]) tensor([[ 7,  6,  7,  3,  5, 19,  5]])\n",
            "tensor([[ 0,  7,  6,  7,  3,  5, 19,  5]]) tensor([[ 7,  6,  7,  3,  5, 19,  5,  1]])\n",
            "tensor([[ 0,  7,  6,  7,  3,  5, 19,  5,  1]]) tensor([[ 7,  6,  7,  3,  5, 19,  5,  1,  2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for source, target in create_train_batch_v2(vocab, text='kek lol', context_length=30):\n",
        "  print(source, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJP8hsEc6gB6",
        "outputId": "ed049274-c151-4f29-e7aa-da2e8179edf0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0]]) tensor([7])\n",
            "tensor([[0, 7]]) tensor([6])\n",
            "tensor([[0, 7, 6]]) tensor([7])\n",
            "tensor([[0, 7, 6, 7]]) tensor([3])\n",
            "tensor([[0, 7, 6, 7, 3]]) tensor([5])\n",
            "tensor([[0, 7, 6, 7, 3, 5]]) tensor([19])\n",
            "tensor([[ 0,  7,  6,  7,  3,  5, 19]]) tensor([5])\n",
            "tensor([[ 0,  7,  6,  7,  3,  5, 19,  5]]) tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# v1\n",
        "dataset = NamesDataset('men_names.txt')\n",
        "\n",
        "lm = CharLanguageModel(\n",
        "    dataset.vocab,\n",
        "    embedding_dim=256,\n",
        "    hidden_size=128,\n",
        "    num_layers=2,\n",
        "    dropout=0.2\n",
        ")\n",
        "optimizer = torch.optim.Adam(lm.parameters(), lr=1e-3)\n",
        "critetia = nn.CrossEntropyLoss()\n",
        "\n",
        "for i in range(75):\n",
        "  epoch_loss = 0\n",
        "  hidden_and_cell = lm.init_hidden_and_cell(batch_size=1)\n",
        "\n",
        "  for text in dataset.all_texts:\n",
        "    # print(text)\n",
        "    for source, target in create_train_batch(vocab, text=text):\n",
        "      output, hidden_and_cell = lm(source, hidden_and_cell)\n",
        "      output = output.reshape(-1, output.shape[-1])\n",
        "      target = target.squeeze(0)\n",
        "      # print(output.shape, hidden_and_cell[0].shape, hidden_and_cell[1].shape, target.shape)\n",
        "\n",
        "      loss = critetia(output, target)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(lm.parameters(), max_norm=1)\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  print(i, epoch_loss)\n",
        "\n",
        "\n",
        "# v2\n",
        "# dataset = NamesDataset('men_names.txt')\n",
        "# loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# lm = CharLanguageModel(\n",
        "#     dataset.vocab,\n",
        "#     embedding_dim=256,\n",
        "#     hidden_size=128,\n",
        "#     num_layers=2,\n",
        "#     dropout=0.2\n",
        "# )\n",
        "# optimizer = torch.optim.Adam(lm.parameters(), lr=1e-3)\n",
        "# critetia = nn.CrossEntropyLoss()\n",
        "\n",
        "# for i in range(75):\n",
        "#   epoch_loss = 0\n",
        "#   hidden_and_cell = lm.init_hidden_and_cell(batch_size=1)\n",
        "\n",
        "#   for text in dataset.all_texts:\n",
        "#     # print(text)\n",
        "#     for source, target in create_train_batch_v2(vocab, text=text, context_length=20):\n",
        "#       output, hidden_and_cell = lm(source, hidden_and_cell)\n",
        "#       # output = output.reshape(-1, output.shape[-1])\n",
        "#       output = output[:, -1, :]\n",
        "#       # target = target.squeeze(0)\n",
        "#       # print(source.shape, output.shape, hidden_and_cell[0].shape, hidden_and_cell[1].shape, target.shape)\n",
        "#       # continue\n",
        "\n",
        "#       loss = critetia(output, target)\n",
        "#       optimizer.zero_grad()\n",
        "#       loss.backward()\n",
        "#       nn.utils.clip_grad_norm_(lm.parameters(), max_norm=1)\n",
        "#       optimizer.step()\n",
        "\n",
        "#       epoch_loss += loss.item()\n",
        "\n",
        "#   print(i, epoch_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlCuW6YfvVoK",
        "outputId": "34f1bf65-b5eb-4733-a901-d27b84a73ac9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 2439.9266880489886\n",
            "1 2051.3260832317173\n",
            "2 1835.9346726685762\n",
            "3 1654.7054427862167\n",
            "4 1536.3987664282322\n",
            "5 1457.0974049717188\n",
            "6 1363.8486453294754\n",
            "7 1321.1771288067102\n",
            "8 1305.033798918128\n",
            "9 1304.5869552195072\n",
            "10 1238.4669582247734\n",
            "11 1255.7723271250725\n",
            "12 1254.858741775155\n",
            "13 1241.966863706708\n",
            "14 1249.899423778057\n",
            "15 1268.8082291781902\n",
            "16 1255.221139267087\n",
            "17 1253.752209275961\n",
            "18 1245.8099597617984\n",
            "19 1250.8025499284267\n",
            "20 1227.5297582000494\n",
            "21 1276.5520815253258\n",
            "22 1285.7849006056786\n",
            "23 1265.8328055143356\n",
            "24 1259.0039042979479\n",
            "25 1245.3482677787542\n",
            "26 1179.2792533785105\n",
            "27 1215.2591548860073\n",
            "28 1241.856218084693\n",
            "29 1188.795037433505\n",
            "30 1180.30099003762\n",
            "31 1198.9388080388308\n",
            "32 1211.1943154633045\n",
            "33 1234.778725400567\n",
            "34 1211.4568966329098\n",
            "35 1218.193317323923\n",
            "36 1196.542737364769\n",
            "37 1178.543487712741\n",
            "38 1201.3524334281683\n",
            "39 1157.7873871698976\n",
            "40 1184.8327914774418\n",
            "41 1204.8317591696978\n",
            "42 1232.977692231536\n",
            "43 1187.166173428297\n",
            "44 1188.979077488184\n",
            "45 1211.8136064708233\n",
            "46 1215.7222876548767\n",
            "47 1208.6250274330378\n",
            "48 1175.3976331204176\n",
            "49 1199.2346514761448\n",
            "50 1188.5976486504078\n",
            "51 1184.8569393008947\n",
            "52 1214.1588460505009\n",
            "53 1157.7340052723885\n",
            "54 1155.2285859286785\n",
            "55 1180.590619519353\n",
            "56 1203.174210935831\n",
            "57 1213.5710581541061\n",
            "58 1149.7017075121403\n",
            "59 1193.0205961167812\n",
            "60 1192.5877405256033\n",
            "61 1196.6146118938923\n",
            "62 1187.2222366929054\n",
            "63 1209.7516154944897\n",
            "64 1161.7309869807214\n",
            "65 1149.218935355544\n",
            "66 1165.0328990072012\n",
            "67 1180.4459389597178\n",
            "68 1201.3185718357563\n",
            "69 1189.7815823554993\n",
            "70 1207.249911159277\n",
            "71 1168.0823594927788\n",
            "72 1190.993179321289\n",
            "73 1158.0496655479074\n",
            "74 1162.3130040168762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter\n",
        "\n",
        "\n",
        "@torch.inference_mode\n",
        "def generate(\n",
        "    vocab: t.Dict[str, int],\n",
        "    model: nn.Module,\n",
        "    prompt: str,\n",
        "    temperature: float = 1.0,\n",
        "    max_tokens: int = 20,\n",
        "    top_k: int = 5\n",
        ") -> str:\n",
        "  model.eval()\n",
        "  hidden_and_cell = model.init_hidden_and_cell(batch_size=1)\n",
        "  prompt_ids = text_to_ids(vocab, [prompt], max_len=len(prompt) + 2)[0][:-1]\n",
        "  prompt_ids_pt = torch.LongTensor([prompt_ids])\n",
        "\n",
        "  for _ in range(max_tokens):\n",
        "    output, hidden_and_cell = model(prompt_ids_pt, hidden_and_cell)\n",
        "    topk_v, topk_idx = torch.topk(output[:, -1, :], k=top_k, dim=1)\n",
        "\n",
        "    if temperature > 0.:\n",
        "      topk_v = topk_v / temperature\n",
        "      probs = nn.Softmax(dim=1)(topk_v)\n",
        "\n",
        "      next_index = torch.multinomial(probs, num_samples=1)[0].item()\n",
        "      next_char = topk_idx[0, next_index].item()\n",
        "    else:\n",
        "      next_char = torch.argmax(output[:, -1, :], dim=1).item()\n",
        "\n",
        "    prompt_ids_pt = torch.cat([prompt_ids_pt, torch.LongTensor([[next_char]])], dim=1)\n",
        "\n",
        "    if next_char == vocab['<end>']:\n",
        "      break\n",
        "\n",
        "  generated_ids = prompt_ids_pt.detach().tolist()\n",
        "  generated_tokens = ids_to_text(vocab, generated_ids)[0]\n",
        "  return ''.join(generated_tokens)\n",
        "\n",
        "t1 = perf_counter()\n",
        "\n",
        "for _ in range(10):\n",
        "  generated_text = generate(vocab, lm, prompt='N', temperature=0.9)\n",
        "  print(generated_text)\n",
        "\n",
        "t2 = perf_counter()\n",
        "\n",
        "print('\\ntime took', t2 - t1, 'sec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRfZYT_B0jkw",
        "outputId": "3babffef-77a9-4ab9-defc-5b7cd87899bc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start>Nestor<end>\n",
            "<start>Novel<end>\n",
            "<start>Nikolay<end>\n",
            "<start>Nikolay<end>\n",
            "<start>Nikita<end>\n",
            "<start>Nestor<end>\n",
            "<start>Nestor<end>\n",
            "<start>Novel<end>\n",
            "<start>Nikolay<end>\n",
            "<start>Nestor<end>\n",
            "\n",
            "time took 0.0638898170000175 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F7AADzn-kDFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}